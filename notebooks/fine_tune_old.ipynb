{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_model_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"knkarthick/dialogsum\"\n",
    "MODEL_NAME = \"google/flan-t5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16) # might want float32 for MPS\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 247577856\n",
      "Trainable parameters: 247577856\n",
      "Percentage of trainable parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "total_params, trainable_params = print_number_of_model_parameters(model)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(f\"Percentage of trainable parameters: {trainable_params / total_params * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n_shot_summary_prompt(example_ids=None, summarize_id=0, data=dataset, my_set='test'):\n",
    "    prompt = ''\n",
    "    if example_ids:\n",
    "        for i in example_ids:\n",
    "            dialogue = data[my_set]['dialogue'][i]\n",
    "            human_summary = data[my_set]['summary'][i]\n",
    "    \n",
    "            prompt += f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\n",
    "{human_summary}\n",
    "\"\"\"\n",
    "        \n",
    "    dialogue = data[my_set]['dialogue'][summarize_id]\n",
    "\n",
    "    prompt += f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "    return prompt\n",
    "    \n",
    "\n",
    "def get_model_completion(prompt, tokenizer=tokenizer, model=model, gen_config=None, \n",
    "                         do_sample=False, max_new_tokens=1000, num_beams=1):\n",
    "    sentence_encoded = tokenizer(prompt, return_tensors='pt').to('mps') \n",
    "    if not hasattr(model, 'base_model'):\n",
    "        completion = model.generate(sentence_encoded.input_ids,\n",
    "                               num_beams=num_beams,\n",
    "                               do_sample=do_sample,\n",
    "                               max_new_tokens=max_new_tokens,\n",
    "                               generation_config=gen_config)[0]\n",
    "    else: # need only kwargs for PEFT models\n",
    "        completion = model.generate(input_ids=sentence_encoded.input_ids,\n",
    "                               num_beams=num_beams,\n",
    "                               do_sample=do_sample,\n",
    "                               max_new_tokens=max_new_tokens,\n",
    "                               generation_config=gen_config)[0]\n",
    "    return tokenizer.decode(completion, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = make_n_shot_summary_prompt(summarize_id=200, data=dataset)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Person1#: I'm thinking of upgrading my computer.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'DIA', 'LOG', 'UE', ':', '▁#', 'P', 'erson', '1', '#', ':', '▁Have', '▁you', '▁considered', '▁upgrading', '▁your', '▁system', '?', '▁#', 'P', 'erson', '2', '#', ':', '▁Yes', ',', '▁but', '▁I', \"'\", 'm', '▁not', '▁sure', '▁what', '▁exactly', '▁I', '▁would', '▁need', '.', '▁#', 'P', 'erson', '1', '#', ':', '▁You', '▁could', '▁consider', '▁adding', '▁', 'a', '▁painting', '▁program', '▁to', '▁your', '▁software', '.', '▁It', '▁would', '▁allow', '▁you', '▁to', '▁make', '▁up', '▁your', '▁own', '▁fly', 'ers', '▁and', '▁banner', 's', '▁for', '▁advertising', '.', '▁#', 'P', 'erson', '2', '#', ':', '▁That', '▁would', '▁be', '▁', 'a', '▁', 'definite', '▁bonus', '.', '▁#', 'P', 'erson', '1', '#', ':', '▁You', '▁might', '▁also', '▁want', '▁to', '▁upgrade', '▁your', '▁hardware', '▁because', '▁it', '▁is', '▁pretty', '▁outdated', '▁now', '.', '▁#', 'P', 'erson', '2', '#', ':', '▁How', '▁can', '▁we', '▁do', '▁that', '?', '▁#', 'P', 'erson', '1', '#', ':', '▁You', \"'\", 'd', '▁probably', '▁need', '▁', 'a', '▁faster', '▁processor', ',', '▁to', '▁begin', '▁with', '.', '▁And', '▁you', '▁also', '▁need', '▁', 'a', '▁more', '▁powerful', '▁hard', '▁disc', ',', '▁more', '▁memory', '▁and', '▁', 'a', '▁faster', '▁mode', 'm', '.', '▁Do', '▁you', '▁have', '▁', 'a', '▁CD', '-', 'ROM', '▁drive', '?', '▁#', 'P', 'erson', '2', '#', ':', '▁No', '.', '▁#', 'P', 'erson', '1', '#', ':', '▁The', 'n', '▁you', '▁might', '▁want', '▁to', '▁add', '▁', 'a', '▁CD', '-', 'ROM', '▁drive', '▁too', ',', '▁because', '▁most', '▁new', '▁software', '▁programs', '▁are', '▁coming', '▁out', '▁on', '▁C', 'd', 's', '.', '▁#', 'P', 'erson', '2', '#', ':', '▁That', '▁sounds', '▁great', '.', '▁Thanks', '.', '▁', 'SU', 'MM', 'ARY', ':', '▁', '</s>']\n"
     ]
    }
   ],
   "source": [
    "sentence_encoded = tokenizer(prompt, return_tensors='pt')\n",
    "tokens = tokenizer.convert_ids_to_tokens(sentence_encoded.input_ids[0])\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    \"\"\"Tokenizes the input and output text for the model, \n",
    "    including a hardcoded prompt to summarize the conversation.\"\"\"\n",
    "    \n",
    "    start_prompt = \"Summarize the following conversation.\\n\\n\"\n",
    "    end_prompt = \"\\n\\nSummary: \"\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example['dialogue']]\n",
    "    output = tokenizer(prompt, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    output['labels'] = tokenizer(example['summary'], truncation=True, padding='max_length', return_tensors='pt').input_ids\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2c1b4996f045548279f11ae117e662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, \n",
    "                                remove_columns=['id', 'topic', 'dialogue', 'summary']\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381c85b199704317befe34f22d8b8f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8011dd2fc092444e993402a3f689d328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b587b65f6b1b47a8be0e4808d1ec7f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_small = tokenized_dataset.filter(lambda example, index: index % 10 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1246\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32, #16,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 251116800\n",
      "Trainable parameters: 3538944\n",
      "Percentage of trainable parameters: 1.41%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, lora_config) # modifies base model?\n",
    "total_params, trainable_params = print_number_of_model_parameters(peft_model)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(f\"Percentage of trainable parameters: {trainable_params / total_params * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/peft-dialogue-summary-training-{timestamp}\"\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-3,\n",
    "    logging_steps=20,\n",
    "    per_device_train_batch_size=2,\n",
    "    # fp16=True,  # for mixed-precision training, but doesn't work on apple silicon\n",
    "    max_steps=-1, \n",
    "    label_names=[\"labels\"],\n",
    "    include_num_input_tokens_seen=True\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    #eval_dataset=tokenized_dataset_small,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer._train_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3538' max='6230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3538/6230 41:48 < 31:49, 1.41 it/s, Epoch 0.57/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>26.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.838700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.281500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.454600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.783500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.293500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.339600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.852600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.334800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.302800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.326600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.291100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.298500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.304400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.324100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.311100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.290900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.301500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.269900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.300300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.303400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.265500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.280200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.280900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.286500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.261200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.300500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.293800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.334500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.394600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.348700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.300500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.319200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.300200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.287900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.306800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.296500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.294500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.314800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.291900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.289800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.287700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.277200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.331300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.332800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.293800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.298700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.315200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.301100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.329600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.335700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.330600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.376100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.331700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.337000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.333200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.347800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.363600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.448200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.466500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpeft_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# CPU: Took 24 minutes to do 1 step which is 8 samples\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# GPU: Took < 1 minute to do 125 samples\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# GPU: Took 8:27 minutes to do 1250 samples\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/accelerate/utils/memory.py:166\u001b[39m, in \u001b[36mfind_executable_batch_size.<locals>.decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo executable batch size found, reached zero.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/transformers/trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2553\u001b[39m context = (\n\u001b[32m   2554\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2558\u001b[39m )\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/transformers/trainer.py:3782\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3779\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3780\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3782\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3784\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/accelerate/accelerator.py:2454\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2452\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2454\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "peft_trainer.train()\n",
    "# CPU: Took 24 minutes to do 1 step which is 8 samples\n",
    "# GPU: Took < 1 minute to do 125 samples\n",
    "# GPU: Took 8:27 minutes to do 1250 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peft_model.save_pretrained('../models/peft-dialogue-summary-training-{timestamp}_lora_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_id = 200\n",
    "prompt = make_n_shot_summary_prompt(summarize_id=my_id, data=dataset)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Person2# thinks upgrading to #Person1#'s system like being able to make up Flyers for advertising has something to do with #Person2#'s hardware, and #Person2#'s hardware.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.manual_seed(42)\n",
    "sentence_encoded = tokenizer(prompt, return_tensors='pt').to('mps')  # Move the entire batch to MPS\n",
    "peft_model = peft_model.to(device)\n",
    "model_orig = model_orig.to(device) \n",
    "completion = peft_model.generate(input_ids=sentence_encoded.input_ids,\n",
    "                            num_beams=1,\n",
    "                            do_sample=True,\n",
    "                            max_new_tokens=1000,\n",
    "                            generation_config=None)[0]  # No need to call .to('mps') again\n",
    "tokenizer.decode(completion, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint 3000, ID 201\n",
    "\n",
    "\"#Person2# invites #Person2# from Mexico to the Holiday Inn. #Person1# thinks it has something from #Person1#'s career in foreign country. #Person2#'s daughter the name of #Person1# and #Person1# has back Columbias heritage.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(peft_model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The flight is scheduled to arrive at the Holiday Inn in China.\n"
     ]
    }
   ],
   "source": [
    "completion = get_model_completion(prompt, model=model_orig)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m peft_model.eval()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m completion = \u001b[43mget_model_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpeft_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mget_model_completion\u001b[39m\u001b[34m(prompt, tokenizer, model, gen_config, do_sample, max_new_tokens, num_beams)\u001b[39m\n\u001b[32m     34\u001b[39m     completion = model.generate(sentence_encoded.input_ids,\n\u001b[32m     35\u001b[39m                            num_beams=num_beams,\n\u001b[32m     36\u001b[39m                            do_sample=do_sample,\n\u001b[32m     37\u001b[39m                            max_new_tokens=max_new_tokens,\n\u001b[32m     38\u001b[39m                            generation_config=gen_config)[\u001b[32m0\u001b[39m]\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# need only kwargs for PEFT models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     completion = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43msentence_encoded\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_config\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.decode(completion, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/peft/peft_model.py:2145\u001b[39m, in \u001b[36mPeftModelForSeq2SeqLM.generate\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   2143\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(**kwargs):\n\u001b[32m   2144\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m2145\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/transformers/generation/utils.py:2278\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2274\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[32m   2277\u001b[39m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2278\u001b[39m     model_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2279\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[32m   2280\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2282\u001b[39m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[32m   2283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/transformers/generation/utils.py:777\u001b[39m, in \u001b[36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[39m\u001b[34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[39m\n\u001b[32m    775\u001b[39m encoder_kwargs[\u001b[33m\"\u001b[39m\u001b[33mreturn_dict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    776\u001b[39m encoder_kwargs[model_input_name] = inputs_tensor\n\u001b[32m--> \u001b[39m\u001b[32m777\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m]: ModelOutput = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1009\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1007\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1008\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m batch_size, seq_length = input_shape\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_explore/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "peft_model.eval()\n",
    "completion = get_model_completion(prompt, model=peft_model)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Person1# helps #Person2# to choose a new phone.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][my_id]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight\n",
      "encoder.block.0.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight\n",
      "encoder.block.0.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
      "encoder.block.0.layer.0.layer_norm.weight\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.0.layer.1.layer_norm.weight\n",
      "encoder.block.1.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight\n",
      "encoder.block.1.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight\n",
      "encoder.block.1.layer.0.layer_norm.weight\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.1.layer.1.layer_norm.weight\n",
      "encoder.block.2.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight\n",
      "encoder.block.2.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight\n",
      "encoder.block.2.layer.0.layer_norm.weight\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.2.layer.1.layer_norm.weight\n",
      "encoder.block.3.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight\n",
      "encoder.block.3.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight\n",
      "encoder.block.3.layer.0.layer_norm.weight\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.3.layer.1.layer_norm.weight\n",
      "encoder.block.4.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight\n",
      "encoder.block.4.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight\n",
      "encoder.block.4.layer.0.layer_norm.weight\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.4.layer.1.layer_norm.weight\n",
      "encoder.block.5.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight\n",
      "encoder.block.5.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight\n",
      "encoder.block.5.layer.0.layer_norm.weight\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.5.layer.1.layer_norm.weight\n",
      "encoder.block.6.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight\n",
      "encoder.block.6.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight\n",
      "encoder.block.6.layer.0.layer_norm.weight\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.6.layer.1.layer_norm.weight\n",
      "encoder.block.7.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight\n",
      "encoder.block.7.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight\n",
      "encoder.block.7.layer.0.layer_norm.weight\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.7.layer.1.layer_norm.weight\n",
      "encoder.block.8.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight\n",
      "encoder.block.8.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight\n",
      "encoder.block.8.layer.0.layer_norm.weight\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.8.layer.1.layer_norm.weight\n",
      "encoder.block.9.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight\n",
      "encoder.block.9.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight\n",
      "encoder.block.9.layer.0.layer_norm.weight\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.9.layer.1.layer_norm.weight\n",
      "encoder.block.10.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight\n",
      "encoder.block.10.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight\n",
      "encoder.block.10.layer.0.layer_norm.weight\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.10.layer.1.layer_norm.weight\n",
      "encoder.block.11.layer.0.SelfAttention.q.base_layer.weight\n",
      "encoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "encoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight\n",
      "encoder.block.11.layer.0.SelfAttention.v.base_layer.weight\n",
      "encoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "encoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight\n",
      "encoder.block.11.layer.0.layer_norm.weight\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_0.weight\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_1.weight\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight\n",
      "encoder.block.11.layer.1.layer_norm.weight\n",
      "encoder.final_layer_norm.weight\n",
      "decoder.block.0.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight\n",
      "decoder.block.0.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
      "decoder.block.0.layer.0.layer_norm.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.0.layer.1.layer_norm.weight\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.0.layer.2.layer_norm.weight\n",
      "decoder.block.1.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight\n",
      "decoder.block.1.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight\n",
      "decoder.block.1.layer.0.layer_norm.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.1.layer.1.layer_norm.weight\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.1.layer.2.layer_norm.weight\n",
      "decoder.block.2.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight\n",
      "decoder.block.2.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight\n",
      "decoder.block.2.layer.0.layer_norm.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.2.layer.1.layer_norm.weight\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.2.layer.2.layer_norm.weight\n",
      "decoder.block.3.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight\n",
      "decoder.block.3.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight\n",
      "decoder.block.3.layer.0.layer_norm.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.3.layer.1.layer_norm.weight\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.3.layer.2.layer_norm.weight\n",
      "decoder.block.4.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight\n",
      "decoder.block.4.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight\n",
      "decoder.block.4.layer.0.layer_norm.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.4.layer.1.layer_norm.weight\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.4.layer.2.layer_norm.weight\n",
      "decoder.block.5.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight\n",
      "decoder.block.5.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight\n",
      "decoder.block.5.layer.0.layer_norm.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.5.layer.1.layer_norm.weight\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.5.layer.2.layer_norm.weight\n",
      "decoder.block.6.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight\n",
      "decoder.block.6.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.6.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.6.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight\n",
      "decoder.block.6.layer.0.layer_norm.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.6.layer.1.layer_norm.weight\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.6.layer.2.layer_norm.weight\n",
      "decoder.block.7.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight\n",
      "decoder.block.7.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.7.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.7.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight\n",
      "decoder.block.7.layer.0.layer_norm.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.7.layer.1.layer_norm.weight\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.7.layer.2.layer_norm.weight\n",
      "decoder.block.8.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight\n",
      "decoder.block.8.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.8.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.8.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight\n",
      "decoder.block.8.layer.0.layer_norm.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.8.layer.1.layer_norm.weight\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.8.layer.2.layer_norm.weight\n",
      "decoder.block.9.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight\n",
      "decoder.block.9.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.9.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.9.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight\n",
      "decoder.block.9.layer.0.layer_norm.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.9.layer.1.layer_norm.weight\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.9.layer.2.layer_norm.weight\n",
      "decoder.block.10.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight\n",
      "decoder.block.10.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.10.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.10.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight\n",
      "decoder.block.10.layer.0.layer_norm.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.10.layer.1.layer_norm.weight\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.10.layer.2.layer_norm.weight\n",
      "decoder.block.11.layer.0.SelfAttention.q.base_layer.weight\n",
      "decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight\n",
      "decoder.block.11.layer.0.SelfAttention.v.base_layer.weight\n",
      "decoder.block.11.layer.0.SelfAttention.v.lora_A.default.weight\n",
      "decoder.block.11.layer.0.SelfAttention.v.lora_B.default.weight\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight\n",
      "decoder.block.11.layer.0.layer_norm.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.q.base_layer.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.v.base_layer.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.v.lora_A.default.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.v.lora_B.default.weight\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight\n",
      "decoder.block.11.layer.1.layer_norm.weight\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_0.weight\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_1.weight\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight\n",
      "decoder.block.11.layer.2.layer_norm.weight\n",
      "decoder.final_layer_norm.weight\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "for name, _ in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "model_orig = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeromh/miniforge3/envs/llm_explore/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "peft_model = PeftModel.from_pretrained(model,\n",
    "    \"../models/peft-dialogue-summary-training-2025-05-08_21-14-28/checkpoint-3000/\",\n",
    "    torch_device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.load_adapter(\"../models/peft-dialogue-summary-training-2025-05-08_21-14-28/checkpoint-2000/\",\n",
    "                        adapter_name=\"chk-2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.peft_config.keys()\n",
    "peft_model.set_adapter(\"chk-2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15:06 in the video\n",
    "\n",
    "\n",
    "# Need to clean up code (especially re: setting MPS if possible, and use throughout). And functions for prompt completion.\n",
    "# Need to figure out why base model is modified (it now has lora params and a base_model attribute). Why? Is it peft?\n",
    "\n",
    "# Why does a lot of the test data repeat? Check this right after loading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
